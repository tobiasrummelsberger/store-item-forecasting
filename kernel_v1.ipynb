{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "**Reading the data and specifying the target to predict.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "train_key = 'sales'\n",
    "\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "\n",
    "X = train.drop(columns=[train_key])\n",
    "y = train[train_key]\n",
    "\n",
    "X_pred = test\n",
    "submissionId = X_pred.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "402808b656d5b27baceaa24ce33262de426c71cc"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "%matplotlib inline\n",
    "\n",
    "def negative_mean_absolute_percentage_error(estimator, X, y_true):\n",
    "    y_pred = estimator.predict(X)\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return -(np.mean(np.abs((y_true - y_pred) / y_true)) * 100)\n",
    "\n",
    "def binarize_stores(X_train, X_test, X_pred):\n",
    "    X_train['store'] = X_train['store'].astype(str)\n",
    "    X_test['store'] = X_test['store'].astype(str)\n",
    "    X_pred['store'] = X_pred['store'].astype(str)\n",
    "    \n",
    "    lbinarizer = LabelBinarizer()\n",
    "    lbinarizer.fit(X_train['store'])\n",
    "    \n",
    "    binarized_values_train = pd.DataFrame(data=lbinarizer.transform(X_train['store']),\n",
    "                                        index=X_train.index,\n",
    "                                        columns=['store_'+column for column in lbinarizer.classes_])\n",
    "    X_train = pd.concat(objs=[X_train, binarized_values_train], axis=1)\n",
    "    \n",
    "    binarized_values_test = pd.DataFrame(data=lbinarizer.transform(X_test['store']),\n",
    "                                        index=X_test.index,\n",
    "                                        columns=['store_'+column for column in lbinarizer.classes_])\n",
    "    X_test = pd.concat(objs=[X_test, binarized_values_test], axis=1)\n",
    "    \n",
    "    binarized_values_pred = pd.DataFrame(data=lbinarizer.transform(X_pred['store']),\n",
    "                                        index=X_pred.index,\n",
    "                                        columns=['store_'+column for column in lbinarizer.classes_])\n",
    "    X_pred = pd.concat(objs=[X_pred, binarized_values_pred], axis=1)\n",
    "    \n",
    "    X_train.drop(columns='store', inplace=True)\n",
    "    X_test.drop(columns='store', inplace=True)\n",
    "    X_pred.drop(columns='store', inplace=True)\n",
    "    \n",
    "    return X_train, X_test, X_pred\n",
    "\n",
    "def binarize_items(X_train, X_test, X_pred):\n",
    "    X_train['item'] = X_train['item'].astype(str)\n",
    "    X_test['item'] = X_test['item'].astype(str)\n",
    "    X_pred['item'] = X_pred['item'].astype(str)\n",
    "    \n",
    "    lbinarizer = LabelBinarizer()\n",
    "    lbinarizer.fit(X_train['item'])\n",
    "    \n",
    "    binarized_values_train = pd.DataFrame(data=lbinarizer.transform(X_train['item']),\n",
    "                                        index=X_train.index,\n",
    "                                        columns=['item_'+column for column in lbinarizer.classes_])\n",
    "    X_train = pd.concat(objs=[X_train, binarized_values_train], axis=1)\n",
    "    \n",
    "    binarized_values_test = pd.DataFrame(data=lbinarizer.transform(X_test['item']),\n",
    "                                        index=X_test.index,\n",
    "                                        columns=['item_'+column for column in lbinarizer.classes_])\n",
    "    X_test = pd.concat(objs=[X_test, binarized_values_test], axis=1)\n",
    "    \n",
    "    binarized_values_pred = pd.DataFrame(data=lbinarizer.transform(X_pred['item']),\n",
    "                                        index=X_pred.index,\n",
    "                                        columns=['item_'+column for column in lbinarizer.classes_])\n",
    "    X_pred = pd.concat(objs=[X_pred, binarized_values_pred], axis=1)\n",
    "    \n",
    "    X_train.drop(columns='item', inplace=True)\n",
    "    X_test.drop(columns='item', inplace=True)\n",
    "    X_pred.drop(columns='item', inplace=True)\n",
    "    \n",
    "    return X_train, X_test, X_pred\n",
    "\n",
    "def split_date(*datasets):\n",
    "    for dataset in datasets:\n",
    "        index = dataset.index\n",
    "        dataset['date'] = pd.to_datetime(dataset['date'], format='%Y-%m-%d')\n",
    "        dataset['day'] = pd.DatetimeIndex(dataset['date']).day\n",
    "        dataset['month'] = pd.DatetimeIndex(dataset['date']).month\n",
    "        dataset['year'] = pd.DatetimeIndex(dataset['date']).year\n",
    "        dataset['dow'] = pd.DatetimeIndex(dataset['date']).dayofweek\n",
    "        dataset['cw'] = pd.DatetimeIndex(dataset['date']).weekofyear\n",
    "    return datasets\n",
    "\n",
    "def preprocess_day(*datasets):\n",
    "    for dataset in datasets:\n",
    "        dataset['day_sin'] = np.sin(dataset['day']-1 * (2. * np.pi / 31))\n",
    "        dataset['day_cos'] = np.cos(dataset['day']-1 * (2. * np.pi / 31))\n",
    "        dataset.drop(columns=['day'], inplace=True)\n",
    "    return datasets\n",
    "\n",
    "def preprocess_month(*datasets):\n",
    "    for dataset in datasets:\n",
    "        dataset['month_sin'] = np.sin(dataset['month']-1 * (2. * np.pi / 12))\n",
    "        dataset['month_cos'] = np.cos(dataset['month']-1 * (2. * np.pi / 12))\n",
    "        dataset.drop(columns=['month'], inplace=True)\n",
    "    return datasets\n",
    "\n",
    "def preprocess_dow(*datasets):\n",
    "    for dataset in datasets:\n",
    "        dataset['dow_sin'] = np.sin(dataset['dow'] * (2. * np.pi / 7))\n",
    "        dataset['dow_cos'] = np.cos(dataset['dow'] * (2. * np.pi / 7))\n",
    "        dataset.drop(columns=['dow'], inplace=True)\n",
    "    return datasets\n",
    "    \n",
    "def preprocess_cw(*datasets):\n",
    "    for dataset in datasets:\n",
    "        dataset['cw_sin'] = np.sin(dataset['cw']-1 * (2. * np.pi / 53))\n",
    "        dataset['cw_cos'] = np.cos(dataset['cw']-1 * (2. * np.pi / 53))\n",
    "        dataset.drop(columns=['cw'], inplace=True)\n",
    "    return datasets\n",
    "\n",
    "def plot_by_date(X, y):\n",
    "    X['sales'] = y\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = (12, 9) # (w, h)\n",
    "    plt.subplot(2,2, 1)\n",
    "    plt.title('Sales by Day of Week')\n",
    "    data_by_dow = X.groupby(['dow']).aggregate(np.mean)\n",
    "    plt.plot(data_by_dow.index, data_by_dow['sales'], linestyle=':', markersize=0.1)\n",
    "\n",
    "    plt.subplot(2,2, 2)\n",
    "    plt.title('Sales by Calendar Week')\n",
    "    data_by_cw = X.groupby(['cw']).aggregate(np.mean)\n",
    "    plt.plot(data_by_cw.index, data_by_cw['sales'], linestyle=':', markersize=0.1)\n",
    "    \n",
    "    plt.subplot(2,2, 3)\n",
    "    plt.title('Sales by Month')\n",
    "    data_by_dow = X.groupby(['month']).aggregate(np.mean)\n",
    "    plt.plot(data_by_dow.index, data_by_dow['sales'], linestyle=':', markersize=0.1)\n",
    "    \n",
    "    plt.subplot(2,2, 4)\n",
    "    plt.title('Sales by Year')\n",
    "    data_by_year = X.groupby(['year']).aggregate(np.mean)\n",
    "    plt.plot(data_by_year.index, data_by_year['sales'], linestyle=':', markersize=0.1)\n",
    "        \n",
    "    X.drop(columns='sales', inplace=True)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def plot_by_date_and_store(X, y):\n",
    "    X['sales'] = y\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = (12, 9) # (w, h)\n",
    "    ax1 = plt.subplot(2,2, 1)\n",
    "    plt.title('Sales per Store by Day of Week')\n",
    "    X.groupby(['dow','store']).count()['sales'].unstack().plot(ax=ax1)\n",
    "    \n",
    "    ax2 = plt.subplot(2,2, 2)\n",
    "    plt.title('Sales per Store by Calendar Week')\n",
    "    X.groupby(['cw','store']).count()['sales'].unstack().plot(ax=ax2)\n",
    "    \n",
    "    ax3 = plt.subplot(2,2, 3)\n",
    "    plt.title('Sales per Store by Month')\n",
    "    X.groupby(['month','store']).count()['sales'].unstack().plot(ax=ax3)\n",
    "    \n",
    "    ax4 = plt.subplot(2,2, 4)\n",
    "    plt.title('Sales per Store by Year')\n",
    "    X.groupby(['year','store']).count()['sales'].unstack().plot(ax=ax4)\n",
    "    \n",
    "    X.drop(columns='sales', inplace=True)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def plot_by_date_and_item(X, y):\n",
    "    X['sales'] = y\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = (12, 9) # (w, h)\n",
    "    ax1 = plt.subplot(2,2, 1)\n",
    "    plt.title('Sales per Item by Day of Week')\n",
    "    X.groupby(['dow','item']).count()['sales'].unstack().plot(ax=ax1)\n",
    "    \n",
    "    ax2 = plt.subplot(2,2, 2)\n",
    "    plt.title('Sales per Item by Calendar Week')\n",
    "    X.groupby(['cw','item']).count()['sales'].unstack().plot(ax=ax2)\n",
    "    \n",
    "    ax3 = plt.subplot(2,2, 3)\n",
    "    plt.title('Sales per Item by Month')\n",
    "    X.groupby(['month','item']).count()['sales'].unstack().plot(ax=ax3)\n",
    "    \n",
    "    ax4 = plt.subplot(2,2, 4)\n",
    "    plt.title('Sales per Item by Year')\n",
    "    X.groupby(['year','item']).count()['sales'].unstack().plot(ax=ax4)\n",
    "    \n",
    "    X.drop(columns='sales', inplace=True)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2f91f451d0daa0ef7139c53091f652a6d79d21a1"
   },
   "source": [
    "**Exploratory Data Analysis**\n",
    "1. Exploring the seasonality in different dimensions (Calendar Week, Day of Week, Month, Year)\n",
    "2. Exploring the seaonality in the same dimensions by stores\n",
    "3. Exploring the seasonality in the same dimensions by item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6f9f47510576016277a70876f8481135a71648b5"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "X_train, X_test, X_pred = split_date(X_train, X_test, X_pred)\n",
    "plot_by_date(X_train, y_train)\n",
    "plot_by_date_and_store(X_train, y_train)\n",
    "plot_by_date_and_item(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "24f01bdc4f8d3589f07516c27285d4b8bbcbb0ba"
   },
   "source": [
    "**Approach I: Machine Learning**\n",
    "Prediction by training the multiple ML algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "62a6ed1b50a04ffe6d0f471305bd1dbedc161fb7"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def train_gridsearch_cv(model, X_train, y_train, param_grid={}):\n",
    "    clf = GridSearchCV(cv=5,\n",
    "                       estimator=model,\n",
    "                       param_grid=param_grid,\n",
    "                       n_jobs=-1,\n",
    "                       verbose=1,\n",
    "                       scoring='neg_mean_squared_error')\n",
    "    clf.fit(X=X_train, y=y_train)\n",
    "    print(\"MSE\", -clf.best_score_)\n",
    "    return clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "39f0e8cf6fffc2b7c1ae71004526e16459876ca0"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, X_pred = binarize_stores(X_train, X_test, X_pred)\n",
    "X_train, X_test, X_pred = binarize_items(X_train, X_test, X_pred)\n",
    "X_train, X_test, X_pred = split_date(X_train, X_test, X_pred)\n",
    "X_train, X_test, X_pred = preprocess_day(X_train, X_test, X_pred)\n",
    "X_train, X_test, X_pred = preprocess_month(X_train, X_test, X_pred)\n",
    "\n",
    "X_train.drop(columns='date', inplace=True)\n",
    "X_test.drop(columns='date', inplace=True)\n",
    "X_pred.drop(columns='date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fc1282c6ea4a07dafa68d8143a8ee9ee8ef0e8f2"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "model_el = ElasticNet()\n",
    "model_el.fit(X_train, y_train)\n",
    "\n",
    "print(\"MAPE:\", round(-negative_mean_absolute_percentage_error(estimator=model_el, \n",
    "                                                        X=X_test, \n",
    "                                                        y_true=y_test),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "755cdc613a1da5d1df2eb09ae5a1886f092439ec"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "model_xgb = XGBRegressor()\n",
    "param_grid = {#'eta':[0.2, 0.3, 0.5], \n",
    "              'max_deth':[3, 5], \n",
    "              'learning_rate':[0.01, 0.07], \n",
    "              'n_estimators':[1000,],\n",
    "              'booster':['gbtree',], \n",
    "              #'min_child_weight':[0.5, 1.0, 2.0], \n",
    "              'subsample':[0.7, 1.0],\n",
    "              'random_state':[42,], \n",
    "              'tree_method': ['auto',], \n",
    "              'alpha': [2,],\n",
    "              'gamma': [1,],\n",
    "              'lambda':[1,], \n",
    "              'colsample_bytree': [1,]}\n",
    "train_gridsearch_cv(model=model_xgb, \n",
    "                    X_train=X_train, \n",
    "                    y_train=y_train, \n",
    "                    param_grid=param_grid)\n",
    "\n",
    "print(\"MAPE:\", round(-negative_mean_absolute_percentage_error(estimator=model_xgb, \n",
    "                                                              X=X_test, \n",
    "                                                              y_true=y_test),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1372e1a194d9aa1cb119f48aa48c4cee58827584"
   },
   "source": [
    "**Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b95005b2f7391bf2e80b0577fdc5fe98b813b441"
   },
   "outputs": [],
   "source": [
    "X_pred = X_pred[list(X_train)]\n",
    "submission = pd.DataFrame({'Id': submissionId, 'sales': model_xgb.predict(X_pred)})\n",
    "# you could use any filename. We choose submission here\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
